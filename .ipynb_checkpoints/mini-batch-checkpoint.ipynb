{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#connect to db\n",
    "engine = create_engine('postgresql+psycopg2://power_user:password@52.40.237.213:5432/expedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Real value encoding from [0,1]\n",
    "total_rows_train = 1024389\n",
    "total_rows_test = 1976304\n",
    "\n",
    "def get_min_max(col_name, table_name, tracker):\n",
    "    \"\"\"gets the min and max values for any column and table. \n",
    "    Used to scale real-valued columns to [0,1]\n",
    "    \"\"\"\n",
    "    min_query = \"SELECT MIN(%s) FROM %s\" % (col_name, table_name)\n",
    "    max_query = \"SELECT MAX(%s) FROM %s\" % (col_name, table_name)\n",
    "    mi = pd.read_sql_query(min_query, engine).loc[0,'min']\n",
    "    ma = pd.read_sql_query(max_query, engine).loc[0,'max']\n",
    "    if table_name not in tracker:\n",
    "        tracker[table_name] = {}\n",
    "    tracker[table_name][col_name] = {'min': mi, 'max':ma}\n",
    "    \n",
    "    \n",
    "def get_categories(col_name, table_name, tracker):\n",
    "    \"\"\"gets a list of categories for any column\n",
    "    \"\"\"\n",
    "    query = \"SELECT DISTINCT %s FROM %s\" % (col_name, table_name)\n",
    "    categories = pd.read_sql_query(query, engine).T.as_matrix()[0]\n",
    "    if table_name not in tracker:\n",
    "        tracker[table_name] = {}\n",
    "    tracker[table_name][col_name] = categories\n",
    "\n",
    "def one_hot(df, col_name, categories):\n",
    "    \"\"\"takes a dataframe and col_name and list of categories to transform dataframe into 1-hot\n",
    "    \"\"\"\n",
    "    for category in categories:\n",
    "        result = []\n",
    "        for row in df.loc[:,col_name]:\n",
    "            if(row == category):\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(0)\n",
    "        new_col_name = str(col_name)+\"_\"+str(category)\n",
    "        df[new_col_name] = result\n",
    "    df = df.drop(col_name, 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get min max \n",
    "encoding = {}\n",
    "\n",
    "encoding = {'d1': [-2.3650345777099999, -1.9331240601899999],\n",
    " 'd10': [-2.3598140268100001, -1.85579069491],\n",
    " 'd100': [-2.4009118520800001, -1.80119791098],\n",
    " 'd101': [-2.3878909283, -1.9469432707000001],\n",
    " 'd102': [-2.3423530342699999, -1.89204753319],\n",
    " 'd103': [-2.3698193229000002, -1.3963841081099999],\n",
    " 'd104': [-2.3791108533299998, -1.9730005659000001],\n",
    " 'd105': [-2.3733358526499999, -1.9885597877800001],\n",
    " 'd106': [-2.3960766273499998, -2.1644836729499999],\n",
    " 'd107': [-2.3791108533299998, -1.8626648206700001],\n",
    " 'd108': [-2.2553206381200002, -1.26468172214],\n",
    " 'd109': [-2.3807262799700002, -1.96585891903],\n",
    " 'd11': [-2.3225828659499999, -1.8326702554900001],\n",
    " 'd110': [-2.3894353046100001, -1.5253348040500001],\n",
    " 'd111': [-2.3767000030999998, -2.0911007046700001],\n",
    " 'd112': [-2.3926574117800001, -1.79368091633],\n",
    " 'd113': [-2.3975170284799998, -2.1012900108100001],\n",
    " 'd114': [-2.3742106241599998, -1.4648718576399999],\n",
    " 'd115': [-2.3998021000300001, -1.68959595614],\n",
    " 'd116': [-2.3975905536100002, -2.1060559492199999],\n",
    " 'd117': [-2.3921104617700002, -1.9329458745899999],\n",
    " 'd118': [-2.3942942075500002, -2.01581365943],\n",
    " 'd119': [-2.3986949191, -2.0527998112399999],\n",
    " 'd12': [-2.4009121108100002, -2.0531013425400002],\n",
    " 'd120': [-2.3920412404100002, -2.03434984065],\n",
    " 'd121': [-2.3105433202699999, -1.6507363874300001],\n",
    " 'd122': [-2.3052507268800002, -1.64521542063],\n",
    " 'd123': [-2.4009121108100002, -2.1231645495399998],\n",
    " 'd124': [-2.3891305621000001, -2.0100315128299999],\n",
    " 'd125': [-2.3900271853100001, -2.0626602423399998],\n",
    " 'd126': [-2.3790339498900002, -1.75546383784],\n",
    " 'd127': [-2.3960350889000002, -1.7120968668300001],\n",
    " 'd128': [-2.3399703246499999, -1.7708520116399999],\n",
    " 'd129': [-2.4008367210400001, -1.6934273477899999],\n",
    " 'd13': [-2.3695452974600002, -1.7498696068599999],\n",
    " 'd130': [-2.3588281816999999, -1.5535932377399999],\n",
    " 'd131': [-2.3807262799700002, -1.11614124866],\n",
    " 'd132': [-2.2828769582200001, -1.6459132750300001],\n",
    " 'd133': [-2.3737948819399999, -1.9943442174199999],\n",
    " 'd134': [-2.3791108533299998, -1.88543754478],\n",
    " 'd135': [-2.4009121108100002, -2.1706127405600002],\n",
    " 'd136': [-2.3807262799700002, -1.43076098938],\n",
    " 'd137': [-2.3807262799700002, -1.70587319884],\n",
    " 'd138': [-2.3807262799700002, -1.50541876843],\n",
    " 'd139': [-2.2620685899100001, -1.2781609842499999],\n",
    " 'd14': [-2.3106806291800002, -1.5521295953300001],\n",
    " 'd140': [-2.3845526801700001, -2.0853733670799999],\n",
    " 'd141': [-2.3710061708399999, -0.99738174348099995],\n",
    " 'd142': [-2.3965910859999999, -1.3634340760200001],\n",
    " 'd143': [-2.3999530669500002, -1.93036691982],\n",
    " 'd144': [-2.38811634156, -1.9351391340299999],\n",
    " 'd145': [-2.3942942075500002, -2.0297869703],\n",
    " 'd146': [-2.4006667639899999, -1.4842905834],\n",
    " 'd147': [-2.3987162478899999, -2.0173824846300001],\n",
    " 'd148': [-2.3865854194999998, -2.0353003424299998],\n",
    " 'd149': [-2.3903696303199999, -1.8458223705700001],\n",
    " 'd15': [-2.3994673932700001, -2.0801960213099999],\n",
    " 'd16': [-2.3248056989800001, -1.64312839061],\n",
    " 'd17': [-2.3399303425800002, -1.8480830045900001],\n",
    " 'd18': [-2.38467151033, -1.2611097767599999],\n",
    " 'd19': [-2.3996493079199999, -2.03152794911],\n",
    " 'd2': [-2.3807262799700002, -1.74775716128],\n",
    " 'd20': [-2.3807262799700002, -1.14006604761],\n",
    " 'd21': [-2.3807262799700002, -1.1774113291799999],\n",
    " 'd22': [-2.4005963184799999, -1.78768964077],\n",
    " 'd23': [-2.4009121108100002, -2.1013373307099998],\n",
    " 'd24': [-2.3775726428400001, -2.0054614235299999],\n",
    " 'd25': [-2.39743459511, -1.59546319818],\n",
    " 'd26': [-2.3723419729600002, -1.86419037256],\n",
    " 'd27': [-2.3979811789399998, -1.8229779958800001],\n",
    " 'd28': [-2.3647614556800001, -2.0301229436599999],\n",
    " 'd29': [-2.2509757823299998, -1.6248315814300001],\n",
    " 'd3': [-2.4009121108100002, -1.97740415047],\n",
    " 'd30': [-2.3807262799700002, -1.9761447780900001],\n",
    " 'd31': [-2.4009121108100002, -2.0431118561699999],\n",
    " 'd32': [-2.3998020859800002, -1.96675439821],\n",
    " 'd33': [-2.3986949191, -2.0761489095800001],\n",
    " 'd34': [-2.3926148194599999, -1.8659620938299999],\n",
    " 'd35': [-2.33269945249, -1.84360492274],\n",
    " 'd36': [-2.37655603932, -1.6014912697799999],\n",
    " 'd37': [-2.1824333088099999, -1.1983623215300001],\n",
    " 'd38': [-2.3983138581499999, -1.7923179816100001],\n",
    " 'd39': [-2.3807262799700002, -1.8609219645399999],\n",
    " 'd4': [-2.3807262799700002, -1.92373758757],\n",
    " 'd40': [-2.37056791414, -2.1245402055099998],\n",
    " 'd41': [-2.3151171647200002, -1.7149437493599999],\n",
    " 'd42': [-2.38758990515, -1.9647412548600001],\n",
    " 'd43': [-2.2280063619899999, -1.37464552726],\n",
    " 'd44': [-2.4009121108100002, -1.6277965331199999],\n",
    " 'd45': [-2.3807262799700002, -1.90111724483],\n",
    " 'd46': [-2.3642656927900001, -2.0586713841500002],\n",
    " 'd47': [-2.3978849073999999, -1.8376801082700001],\n",
    " 'd48': [-2.3776937917300001, -1.95870616039],\n",
    " 'd49': [-2.2479732663599998, -1.1788062691700001],\n",
    " 'd5': [-2.3672859996, -1.75833691883],\n",
    " 'd50': [-2.3807262799700002, -1.8667866261899999],\n",
    " 'd51': [-2.3974997599300001, -1.9475851934899999],\n",
    " 'd52': [-2.3598937111899998, -2.04685388543],\n",
    " 'd53': [-2.3524504359799998, -1.3771263150699999],\n",
    " 'd54': [-2.4005337567999998, -1.74151450471],\n",
    " 'd55': [-2.3421048813700001, -1.6319022265300001],\n",
    " 'd56': [-2.3569996138599998, -1.6986090755400001],\n",
    " 'd57': [-2.39701602876, -1.79392045101],\n",
    " 'd58': [-2.3660112692199999, -1.1770962442399999],\n",
    " 'd59': [-2.3931525749500002, -1.9154089919899999],\n",
    " 'd6': [-2.2200674214, -1.3494678286999999],\n",
    " 'd60': [-2.39996621475, -2.0592256977000001],\n",
    " 'd61': [-2.38016972427, -1.9989555720900001],\n",
    " 'd62': [-2.3917607414700002, -1.65268211583],\n",
    " 'd63': [-2.39901503397, -2.03314317238],\n",
    " 'd64': [-2.4005060008500001, -2.0417822928199998],\n",
    " 'd65': [-2.4009121108100002, -2.1467892338899999],\n",
    " 'd66': [-2.3648569319399999, -1.47646979155],\n",
    " 'd67': [-2.39558488071, -1.90208232726],\n",
    " 'd68': [-2.3964564789199998, -1.8863821777600001],\n",
    " 'd69': [-2.39194670953, -1.9469432707000001],\n",
    " 'd7': [-2.39286246081, -1.8231209134199999],\n",
    " 'd70': [-2.4009121108100002, -2.0143053577400001],\n",
    " 'd71': [-2.3807262799700002, -1.2195013163499999],\n",
    " 'd72': [-2.3807262799700002, -2.1733265897299998],\n",
    " 'd73': [-2.3937810720199999, -1.67709641926],\n",
    " 'd74': [-2.2882721682299998, -1.6048613360599999],\n",
    " 'd75': [-2.3218751223499998, -1.8210432425600001],\n",
    " 'd76': [-2.3994087423699999, -1.5139678347900001],\n",
    " 'd77': [-2.3479152604300002, -1.5627915622299999],\n",
    " 'd78': [-2.3855802668299999, -1.7731269037299999],\n",
    " 'd79': [-2.3804939457400001, -1.44809402477],\n",
    " 'd8': [-2.3813874621300002, -1.98010847034],\n",
    " 'd80': [-2.37427046074, -1.47018968522],\n",
    " 'd81': [-2.3918603699599998, -1.88357984672],\n",
    " 'd82': [-2.39790596945, -1.8813328063500001],\n",
    " 'd83': [-2.3723277139899999, -1.9048245038],\n",
    " 'd84': [-2.3080556791000002, -1.86924754578],\n",
    " 'd85': [-2.3468559840799998, -1.9956857781099999],\n",
    " 'd86': [-2.4009121108100002, -2.0865109962899999],\n",
    " 'd87': [-2.3995024679100001, -1.5497105012000001],\n",
    " 'd88': [-2.38797869376, -1.2561935688999999],\n",
    " 'd89': [-2.3929534806800001, -1.9036840408],\n",
    " 'd9': [-2.36345614241, -0.97721871479400002],\n",
    " 'd90': [-2.4003962474399998, -2.0619835047300001],\n",
    " 'd91': [-2.2560230539499999, -1.5112374281900001],\n",
    " 'd92': [-2.39684348178, -1.63235041057],\n",
    " 'd93': [-2.19527566452, -1.25645803381],\n",
    " 'd94': [-2.3819036716199999, -1.3972656431299999],\n",
    " 'd95': [-2.39620789679, -2.1037223913399998],\n",
    " 'd96': [-2.3185751291100001, -1.8791773135900001],\n",
    " 'd97': [-2.3998021000300001, -2.07911862476],\n",
    " 'd98': [-2.3980061260599999, -1.67015053329],\n",
    " 'd99': [-2.3851020245900001, -2.04017888535],\n",
    " 'orig_destination_distance': [0.0055999999999999999, 11720.8809]}\n",
    "\n",
    "# for i in range(1, 150):\n",
    "#     c = 'd' + str(i)\n",
    "#     get_min_max(c, 'destinations', encoding)\n",
    "\n",
    "# get_min_max('orig_destination_distance', 'train_set', encoding)\n",
    "# get_min_max('orig_destination_distance', 'test_set', encoding)\n",
    "\n",
    "    \n",
    "#get categories\n",
    "col_to_1hot = ['site_name',\n",
    " 'posa_continent',\n",
    " 'user_location_country',\n",
    " 'channel',\n",
    " 'hotel_continent',\n",
    " 'hotel_country']\n",
    "\n",
    "for column in col_to_1hot:\n",
    "    get_categories(column, 'train_set', encoding)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loss_acc_plot(train_loss, test_loss, train_acc, \n",
    "                  test_acc, title, batch_size):\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.suptitle(title.title(), fontsize=16)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    t = np.arange(len(train_loss)) * batch_size\n",
    "\n",
    "    train_loss_line, = plt.plot(t, train_loss, linestyle='--', \\\n",
    "                           color = 'r', label='Training Loss')\n",
    "    test_loss_line, = plt.plot(t, test_loss, linestyle='-', \\\n",
    "                           color = 'b', label='Testing Loss')\n",
    "    plt.legend([train_loss_line, test_loss_line], \n",
    "               ['Training Loss', 'Testing Loss'])\n",
    "    plt.title('Train/Test Loss v Training Data Accesses')\n",
    "    plt.xlabel('Training Data Accesses')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.axis([0, 20*batch_size, 0, 0.4])\n",
    "    plt.style.use('ggplot')\n",
    "    plt.subplot(2, 1, 2)\n",
    "    \n",
    "    train_acc_line, = plt.plot(t, train_acc, linestyle='--', \\\n",
    "                           color = 'r', label='Training Acc')\n",
    "    test_acc_line, = plt.plot(t, test_acc, linestyle='-', \\\n",
    "                           color = 'b', label='Testing Acc')\n",
    "    plt.legend([train_acc_line, test_acc_line], \n",
    "               ['Training Acc', 'Testing Acc'])\n",
    "    #plt.axis([0, 20*batch_size, 8000, 11000])\n",
    "    plt.title('Train/Test Acc v Training Data Accesses')\n",
    "    plt.xlabel('Training Data Accesses')\n",
    "    plt.ylabel('Accuracy')\n",
    "    \n",
    "    plt.style.use('ggplot')\n",
    "    plt.subplots_adjust(hspace=.5)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.tensor.signal.pool\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#MAP@n evaluation function taken from https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py\n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#NEURAL NET\n",
    "\n",
    "empty_loss_acc = {'tst_loss': [], 'tst_acc': [], 'tr_acc':[], 'tst_loss': []}\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "        \n",
    "def init_nnet(layer_sizes):\n",
    "    input_var = T.matrix()\n",
    "    target_var = T.ivector()\n",
    "\n",
    "    num_features_train = 650\n",
    "    network = lasagne.layers.InputLayer((None,num_features_train), input_var)\n",
    "\n",
    "    #add desired number of layers\n",
    "    for i in layer_sizes:\n",
    "        network = lasagne.layers.DenseLayer(\n",
    "            network, \n",
    "            i, \n",
    "            nonlinearity = lasagne.nonlinearities.sigmoid)\n",
    "\n",
    "    network = lasagne.layers.DenseLayer(network, \n",
    "                                        100, \n",
    "                                        nonlinearity=lasagne.nonlinearities.softmax)\n",
    "    \n",
    "    return network, input_var, target_var\n",
    "\n",
    "\n",
    "def compute_nnet(network, input_var, target_var, BATCH_SIZE, STEP_SIZE, total_epochs, title, loss_acc):\n",
    "    #CONSTANTS\n",
    "\n",
    "    num_features_train = 650 \n",
    "    total_rows_train = 1024389\n",
    "    total_rows_test = 1976304\n",
    "\n",
    "    num_iter = total_rows_train/BATCH_SIZE\n",
    "\n",
    "    train_orig_destination_distance_avg = 1993.914515 #SELECT AVG(orig_destination_distance) FROM table_name\n",
    "\n",
    "    #END CONSTANTS\n",
    "\n",
    "#     input_var = T.matrix()\n",
    "#     target_var = T.ivector()\n",
    "    num_fea = num_features_train\n",
    "    # Initialize\n",
    "\n",
    "    #This gives the probabilities\n",
    "    prediction = lasagne.layers.get_output(network)\n",
    "\n",
    "    #These are all the parameters of the network\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(\n",
    "        prediction, \n",
    "        target_var)\n",
    "\n",
    "\n",
    "    loss = loss.mean()\n",
    "\n",
    "\n",
    "    updates = lasagne.updates.sgd(loss, params, learning_rate = STEP_SIZE)\n",
    "\n",
    "\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic = True)\n",
    "    test_loss =  lasagne.objectives.categorical_crossentropy(test_prediction, target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "\n",
    "    train_fn = theano.function([input_var, target_var], loss, updates=updates,allow_input_downcast=True)\n",
    "    val_fn = theano.function([input_var, target_var], [test_loss, test_acc],allow_input_downcast=True)\n",
    "\n",
    "\n",
    "\n",
    "    #grad = T.grad(loss, params)\n",
    "\n",
    "    error = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var))\n",
    "\n",
    "    loss_fcn = theano.function([input_var, target_var], \n",
    "                               loss, allow_input_downcast=True)\n",
    "    #grad_fcn = theano.function([input_var, target_var], \n",
    "    #                           grad, allow_input_downcast=True)\n",
    "    pred_fcn = theano.function([input_var], \n",
    "                               T.argmax(test_prediction, axis=1),  \n",
    "                               allow_input_downcast=True)\n",
    "    erro_fcn = theano.function([input_var, target_var], \n",
    "                               error, allow_input_downcast=True)\n",
    "\n",
    "    tr_loss = loss_acc['tr_loss']\n",
    "    tst_loss = loss_acc['tst_loss']\n",
    "    tr_acc = loss_acc['tr_acc']\n",
    "    tst_acc = tst_acc['tst_acc']\n",
    "\n",
    "    for epoch in range(0, total_epochs):\n",
    "        print \"\\nRUNNING EPOCH %d\" % epoch\n",
    "        train_loss = 0\n",
    "\n",
    "        #Testing data setup\n",
    "        ts = pd.read_sql_query(\"\"\"\n",
    "        SELECT \n",
    "            t.hotel_cluster,\n",
    "            t.site_name,\n",
    "            t.posa_continent,\n",
    "            t.user_location_country,\n",
    "            t.is_mobile,\n",
    "            t.is_package,\n",
    "            t.orig_destination_distance,\n",
    "            t.channel,\n",
    "            t.srch_destination_type_id,\n",
    "            t.hotel_continent,\n",
    "            t.hotel_country,\n",
    "            d.*\n",
    "        FROM \n",
    "            test_set t NATURAL INNER JOIN destinations d\n",
    "\n",
    "        WHERE \n",
    "            t.is_booking = 1\n",
    "            AND\n",
    "            random() < 0.05\n",
    "            ;\"\"\", engine)\n",
    "\n",
    "        test_orig_destination_distance_avg = 1678.710641\n",
    "\n",
    "        ts.loc[:,'orig_destination_distance'] = ts.loc[:,'orig_destination_distance'].fillna(test_orig_destination_distance_avg)\n",
    "        ts.loc[:,'orig_destination_distance'] = (ts.loc[:,'orig_destination_distance'] - encoding['orig_destination_distance'][0]) /\\\n",
    "        (encoding['orig_destination_distance'][1] - encoding['orig_destination_distance'][0])\n",
    "\n",
    "        for i in range(1, 150):\n",
    "            c = 'd' + str(i)\n",
    "            mi = encoding[c][0]\n",
    "            ma = encoding[c][1]\n",
    "            ts.loc[:,c] = (ts.loc[:,c] - mi)/(ma - mi)\n",
    "\n",
    "        for col in col_to_1hot:\n",
    "            categories = encoding['train_set'][col]\n",
    "            ts = one_hot(ts, col, categories)\n",
    "\n",
    "        ts = ts.drop('srch_destination_id', axis=1)\n",
    "        test_full = ts.as_matrix()\n",
    "        X_test = test_full[:, 1:]\n",
    "        Y_test = test_full[:, 0]\n",
    "\n",
    "        #Set up training data\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            t.hotel_cluster,\n",
    "            t.site_name,\n",
    "            t.posa_continent,\n",
    "            t.user_location_country,\n",
    "            t.is_mobile,\n",
    "            t.is_package,\n",
    "            t.orig_destination_distance,\n",
    "            t.srch_destination_type_id,\n",
    "            t.channel,\n",
    "            t.hotel_continent,\n",
    "            t.hotel_country,\n",
    "            d.*\n",
    "        FROM \n",
    "            train_set t NATURAL INNER JOIN destinations d\n",
    "\n",
    "        WHERE \n",
    "            t.is_booking = 1\n",
    "            AND\n",
    "            random() < 0.05\n",
    "        \"\"\"\n",
    "        tr = pd.read_sql_query(query, engine)\n",
    "\n",
    "        #scale values\n",
    "        tr.loc[:,'orig_destination_distance'] = tr.loc[:,'orig_destination_distance'].fillna(train_orig_destination_distance_avg)\n",
    "        tr.loc[:,'orig_destination_distance'] = (tr.loc[:,'orig_destination_distance'] - encoding['orig_destination_distance'][0]) /\\\n",
    "        (encoding['orig_destination_distance'][1] - encoding['orig_destination_distance'][0])\n",
    "\n",
    "        for i in range(1, 150):\n",
    "            c = 'd' + str(i)\n",
    "            mi = encoding[c][0]\n",
    "            ma = encoding[c][1]\n",
    "            tr.loc[:,c] = (tr.loc[:,c] - mi)/(ma - mi)\n",
    "\n",
    "        for col in col_to_1hot:\n",
    "            categories = encoding['train_set'][col]\n",
    "            tr = one_hot(tr, col, categories)\n",
    "\n",
    "        tr = tr.drop('srch_destination_id', 1)\n",
    "\n",
    "        #X_train and Y_train\n",
    "        batch_train = tr.as_matrix()\n",
    "        X_train = batch_train[:, 1:]\n",
    "        Y_train = np.array(batch_train[:, 0])\n",
    "        \n",
    "        for batch in iterate_minibatches(X_train, Y_train, BATCH_SIZE, shuffle=True):\n",
    "            inputs, targets = batch\n",
    "            train_loss = train_fn(inputs, targets)\n",
    "        \n",
    "        tl, ta = val_fn(X_train, Y_train)\n",
    "        vl, va = val_fn(X_test, Y_test)\n",
    "        loss_acc['tr_acc'].append(ta)\n",
    "        loss_acc['tr_loss'].append(tl)\n",
    "        loss_acc['tst_acc'].append(va)\n",
    "        loss_acc['tst_loss'].append(vl)\n",
    "    \n",
    "    pred_fcn_top5 = theano.function([input_var], T.argsort(prediction, axis=1))\n",
    "\n",
    "\n",
    "    return pred_fcn_top5, network, loss_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_5(model, y_test):\n",
    "    model.shape\n",
    "    model_rev = np.zeros(model.shape)\n",
    "    for i in range(model.shape[0]):\n",
    "        model_rev[i,:] = model[i,:][::-1]\n",
    "    \n",
    "    model_rev = model_rev[:,:5]\n",
    "    sum_score = 0\n",
    "    for actual, predictions in zip(y_test, model_rev):\n",
    "        predictions = [int(i)for i in predictions]\n",
    "        sum_score += apk([int(actual)], predictions)\n",
    "    total_rows = model.shape[0]\n",
    "    map_k = sum_score/total_rows\n",
    "    return map_k\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is Zero Layer Multi Class Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute_nnet(X_test, Y_test, BATCH_SIZE, STEP_SIZE, total_epochs, layer_sizes, title):\n",
    "#network, BATCH_SIZE, STEP_SIZE, total_epochs, title, loss_acc \n",
    "\n",
    "layer_sizes = []\n",
    "network = init_nnet(layer_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnusedInputError",
     "evalue": "theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: <TensorType(float64, matrix)>.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnusedInputError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-227f7c948a14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_fn_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_nnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Zero Layer Multi Class Logistic Regression'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mempty_loss_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-d4da830d39da>\u001b[0m in \u001b[0;36mcompute_nnet\u001b[1;34m(network, BATCH_SIZE, STEP_SIZE, total_epochs, title, loss_acc)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mtrain_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[0mval_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shikhar/anaconda2/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    320\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shikhar/anaconda2/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shikhar/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1825\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1827\u001b[1;33m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1828\u001b[0m             defaults)\n\u001b[0;32m   1829\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shikhar/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph, output_keys)\u001b[0m\n\u001b[0;32m   1464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1465\u001b[0m         \u001b[1;31m# Check if some input variables are unused\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1466\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_unused_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1468\u001b[0m         \u001b[1;31m# Make a list of (SymbolicInput|SymblicInputKits, indices,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/shikhar/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m_check_unused_inputs\u001b[1;34m(self, inputs, outputs, on_unused_input)\u001b[0m\n\u001b[0;32m   1602\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mon_unused_input\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'raise'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m                     raise UnusedInputError(msg % (inputs.index(i),\n\u001b[1;32m-> 1604\u001b[1;33m                                                   i.variable, err_msg))\n\u001b[0m\u001b[0;32m   1605\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1606\u001b[0m                     raise ValueError(\"Invalid value for keyword \"\n",
      "\u001b[1;31mUnusedInputError\u001b[0m: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 0 is not part of the computational graph needed to compute the outputs: <TensorType(float64, matrix)>.\nTo make this error into a warning, you can pass the parameter on_unused_input='warn' to theano.function. To disable it completely, use on_unused_input='ignore'."
     ]
    }
   ],
   "source": [
    "pred_fn_5, network, loss_acc = compute_nnet(network, 128, 128, 5, 'Zero Layer Multi Class Logistic Regression', empty_loss_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
